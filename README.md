# ğŸ¨ CLIP-Demo: ìì²´ êµ¬í˜„ CLIP ëª¨ë¸

PyTorch Lightningì„ ì‚¬ìš©í•œ ì™„ì „í•œ **ìì²´ êµ¬í˜„ CLIP** (Contrastive Language-Image Pre-training) ëª¨ë¸ì…ë‹ˆë‹¤.

## âœ¨ ì£¼ìš” íŠ¹ì§•

- ğŸ”§ **ì™„ì „ ìì²´ êµ¬í˜„**: OpenAI CLIPì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì²˜ìŒë¶€í„° êµ¬í˜„
- ğŸ—ï¸ **ëª¨ë“ˆí™”ëœ ì•„í‚¤í…ì²˜**: Vision Transformer + Text Transformer
- âš¡ **PyTorch Lightning**: ê¹”ë”í•œ í•™ìŠµ íŒŒì´í”„ë¼ì¸
- ğŸ¯ **Zero-Shot ë¶„ë¥˜**: í•™ìŠµ ì‹œ ë³´ì§€ ëª»í•œ í´ë˜ìŠ¤ë„ ë¶„ë¥˜ ê°€ëŠ¥
- ğŸ“Š **ì™„ì „í•œ í‰ê°€**: Recall@K ë©”íŠ¸ë¦­ ì§€ì›

## ğŸ›ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ì´ë¯¸ì§€ ì…ë ¥    â”‚    â”‚    í…ìŠ¤íŠ¸ ì…ë ¥    â”‚
â”‚   (224Ã—224)     â”‚    â”‚   ("a cat")     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ViT Encoder â”‚        â”‚Text Encoder  â”‚
    â”‚  (12 layers)â”‚        â”‚ (12 layers)  â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Image Embed â”‚        â”‚ Text Embed   â”‚
    â”‚   (512D)   â”‚        â”‚   (512D)     â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚
          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                 â”‚         â”‚
            â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
            â”‚  Cosine Similarity â”‚
            â”‚  Ã— Temperature     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
clip-demo/
â”œâ”€â”€ src/                    # í•µì‹¬ ëª¨ë¸ ì½”ë“œ
â”‚   â”œâ”€â”€ model.py           # CLIP ë©”ì¸ ëª¨ë¸
â”‚   â”œâ”€â”€ image_encoder.py   # Vision Transformer
â”‚   â”œâ”€â”€ text_encoder.py    # Text Transformer + í† í¬ë‚˜ì´ì €
â”‚   â”œâ”€â”€ clip_layers.py     # Transformer ë¸”ë¡ë“¤
â”‚   â”œâ”€â”€ trainer.py         # PyTorch Lightning ëª¨ë“ˆ
â”‚   â”œâ”€â”€ dataset.py         # ë°ì´í„° ë¡œë”
â”‚   â”œâ”€â”€ loss.py           # Contrastive Loss
â”‚   â””â”€â”€ utils.py          # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”œâ”€â”€ script/                # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ train.py          # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ inference.py      # ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ evaluate.py       # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ data/                  # ìƒ˜í”Œ ë°ì´í„°
â”‚   â”œâ”€â”€ train.csv         # í•™ìŠµ ë°ì´í„° ëª©ë¡
â”‚   â””â”€â”€ images/           # ì´ë¯¸ì§€ íŒŒì¼ë“¤
â””â”€â”€ test_model.py         # ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# ë¦¬í¬ì§€í† ë¦¬ í´ë¡ 
git clone https://github.com/yongjoon02/clip-demo.git
cd clip-demo

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install torch torchvision pytorch-lightning pandas pillow transformers
```

### 2. ëª¨ë¸ í…ŒìŠ¤íŠ¸

```bash
# ê¸°ë³¸ ëª¨ë¸ ë™ì‘ í™•ì¸
python test_model.py
```

### 3. í•™ìŠµ ì‹¤í–‰

```bash
# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ í•™ìŠµ
python script/train.py

# ì»¤ìŠ¤í…€ ì„¤ì •
python script/train.py --epochs 10 --batch-size 64 --lr 1e-4
```

### 4. ì¶”ë¡  ì‹¤í–‰

```bash
# Zero-shot ì´ë¯¸ì§€ ë¶„ë¥˜
python script/inference.py --image-dir data/images --classes "cat,dog,car"
```

### 5. ëª¨ë¸ í‰ê°€

```bash
# Recall@K í‰ê°€
python script/evaluate.py --csv data/train.csv --img-root data/images
```

## ğŸ”§ ëª¨ë¸ êµ¬ì„± ìš”ì†Œ

### Vision Transformer (ViT)
- **íŒ¨ì¹˜ í¬ê¸°**: 32Ã—32 (224Ã—224 â†’ 7Ã—7 íŒ¨ì¹˜)
- **ì„ë² ë”© ì°¨ì›**: 768
- **ë ˆì´ì–´ ìˆ˜**: 12
- **ì–´í…ì…˜ í—¤ë“œ**: 12

### Text Transformer
- **ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´**: 77 í† í°
- **ì„ë² ë”© ì°¨ì›**: 512  
- **ë ˆì´ì–´ ìˆ˜**: 12
- **ì–´í…ì…˜ í—¤ë“œ**: 8
- **í† í¬ë‚˜ì´ì €**: ìì²´ êµ¬í˜„ (ê°„ë‹¨í•œ ë¬¸ì ê¸°ë°˜)

### ê³µí†µ ì„ë² ë”© ê³µê°„
- **ì°¨ì›**: 512
- **ì •ê·œí™”**: L2 ì •ê·œí™”
- **ì˜¨ë„ ìŠ¤ì¼€ì¼ë§**: í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°

## ğŸ“Š í•™ìŠµ ê³¼ì •

### Contrastive Learning
```python
# ë°°ì¹˜ ë‚´ì—ì„œ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìŒ ë§¤ì¹­
loss = 0.5 * (
    CrossEntropy(imageâ†’text_logits, diagonal_targets) +
    CrossEntropy(textâ†’image_logits, diagonal_targets)
)
```

### í•™ìŠµ ì„¤ì •
- **ì˜µí‹°ë§ˆì´ì €**: AdamW (Î²â‚=0.9, Î²â‚‚=0.98)
- **í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬**: CosineAnnealingLR
- **ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘**: 1.0
- **ì •ë°€ë„**: FP32

## ğŸ¯ Zero-Shot ë¶„ë¥˜

### ë‹¤ì¤‘ í…œí”Œë¦¿ ì‚¬ìš©
```python
templates = [
    "a photo of a {}.",
    "a blurry photo of a {}.",
    "a close-up of a {}."
]
```

### ë¶„ë¥˜ ê³¼ì •
1. ê° í´ë˜ìŠ¤ë³„ë¡œ ë‹¤ì¤‘ í…œí”Œë¦¿ ì ìš©
2. í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± í›„ í‰ê· í™”
3. ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
4. ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ì˜ í´ë˜ìŠ¤ ì„ íƒ

## ğŸ“ˆ ì„±ëŠ¥ í‰ê°€

### Recall@K ë©”íŠ¸ë¦­
- **Imageâ†’Text**: ì´ë¯¸ì§€ë¡œ í…ìŠ¤íŠ¸ ê²€ìƒ‰
- **Textâ†’Image**: í…ìŠ¤íŠ¸ë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰
- **K=1,5,10**: ìƒìœ„ Kê°œ ê²°ê³¼ ì¤‘ ì •ë‹µ í¬í•¨ë¥ 

## ğŸ” ì˜ˆì œ ê²°ê³¼

```bash
=== ìì²´ êµ¬í˜„ CLIP ëª¨ë¸ í…ŒìŠ¤íŠ¸ ===
âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ: CLIPModel
âœ… í…ìŠ¤íŠ¸ ì„ë² ë”© í¬ê¸°: torch.Size([2, 512])
âœ… ì´ë¯¸ì§€ ì„ë² ë”© í¬ê¸°: torch.Size([2, 512])
âœ… Temperature: 14.2857
ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!
```

## ğŸ› ï¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ëª¨ë¸ ì•„í‚¤í…ì²˜ ë³€ê²½
```python
# script/train.pyì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •
--vision-width 768        # ViT ì„ë² ë”© ì°¨ì›
--vision-layers 12        # ViT ë ˆì´ì–´ ìˆ˜
--text-width 512          # í…ìŠ¤íŠ¸ ì„ë² ë”© ì°¨ì›
--embed-dim 512           # ê³µí†µ ì„ë² ë”© ì°¨ì›
```

### ë°ì´í„°ì…‹ í˜•ì‹
```csv
image_path,caption
image1.jpg,"a photo of a cat"
image2.jpg,"a dog playing in the park"
```

## ğŸ¤ ê¸°ì—¬

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

## ğŸ™ ì°¸ê³  ë¬¸í—Œ

- [Learning Transferable Visual Representations with Contrastive Language-Image Pre-training](https://arxiv.org/abs/2103.00020)
- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)

---

**Made with â¤ï¸ by [yongjoon02](https://github.com/yongjoon02)**
