#!/usr/bin/env python3
# test_inference.py - ìì²´ êµ¬í˜„ CLIP ëª¨ë¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).resolve().parent / "src"))

import torch
from src.model import CLIPModel
from src.dataset import build_image_transform
from PIL import Image

def test_inference():
    print("=== ìì²´ êµ¬í˜„ CLIP ì¶”ë¡  í…ŒìŠ¤íŠ¸ ===")
    
    try:
        # 1. ëª¨ë¸ ìƒì„±
        print("1. ëª¨ë¸ ìƒì„± ì¤‘...")
        model = CLIPModel().eval()
        print("   âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        
        # 2. í´ë˜ìŠ¤ ë° í…œí”Œë¦¿ ì„¤ì •
        classes = ["cat", "dog", "sample"]
        templates = ["a photo of a {}.", "a blurry photo of a {}.", "a close-up of a {}."]
        
        # 3. í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (í…œí”Œë¦¿ í‰ê· )
        print("2. í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘...")
        prompts = [t.format(c) for c in classes for t in templates]
        print(f"   ìƒì„±ëœ í”„ë¡¬í”„íŠ¸: {prompts}")
        
        with torch.no_grad():
            text_tokens = model.text.tokenize(prompts)
            text_emb = model.encode_text(text_tokens)  # (#prompts, D)
            text_emb = text_emb.view(len(classes), -1, text_emb.size(-1)).mean(1)  # (C, D)
            print(f"   âœ… í…ìŠ¤íŠ¸ ì„ë² ë”© í¬ê¸°: {text_emb.shape}")
        
        # 4. ì´ë¯¸ì§€ ë¡œë“œ ë° ë¶„ë¥˜
        print("3. ì´ë¯¸ì§€ ë¶„ë¥˜ ì¤‘...")
        img_path = Path("data/images/image.png")
        
        if img_path.exists():
            transform = build_image_transform(224)
            img = Image.open(img_path).convert("RGB")
            img_tensor = transform(img).unsqueeze(0)
            
            with torch.no_grad():
                img_emb = model.encode_image(img_tensor)
                logits = model.temperature * img_emb @ text_emb.t()
                probs = logits.softmax(-1)
                pred_idx = logits.argmax(-1).item()
                
            print(f"   âœ… ì´ë¯¸ì§€: {img_path}")
            print(f"   âœ… ì˜ˆì¸¡ í´ë˜ìŠ¤: {classes[pred_idx]}")
            print(f"   âœ… í™•ë¥  ë¶„í¬: {dict(zip(classes, probs[0].tolist()))}")
            
        else:
            print(f"   âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŒ: {img_path}")
            print("   ë”ë¯¸ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸...")
            
            dummy_img = torch.randn(1, 3, 224, 224)
            with torch.no_grad():
                img_emb = model.encode_image(dummy_img)
                logits = model.temperature * img_emb @ text_emb.t()
                probs = logits.softmax(-1)
                pred_idx = logits.argmax(-1).item()
                
            print(f"   âœ… ë”ë¯¸ ì´ë¯¸ì§€ ì˜ˆì¸¡ í´ë˜ìŠ¤: {classes[pred_idx]}")
            print(f"   âœ… í™•ë¥  ë¶„í¬: {dict(zip(classes, probs[0].tolist()))}")
        
        print("\nğŸ‰ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"\nâŒ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_inference()
    sys.exit(0 if success else 1) 